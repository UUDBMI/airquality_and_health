{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temporal-Spatial Pollution Distribution in Salt Lake County"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mesowest\n",
    "import importlib\n",
    "from datetime import datetime, date\n",
    "import json\n",
    "import locale\n",
    "import numpy as np\n",
    "import folium\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "import pandas as pd\n",
    "from scipy.interpolate import griddata\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "import seaborn as sns\n",
    "import gzip\n",
    "import json\n",
    "from dateutil.parser import *\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import urllib\n",
    "import matplotlib.mlab as mlab\n",
    "import pickle\n",
    "import matplotlib.tri as tri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First We Need to Identify the Measurement Sites in the County of Interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counties = [\"Weber\", \"Davis\", \"Salt Lake\", \"Summit\", \"Utah\", \"Tooele\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "format": "row"
   },
   "outputs": [],
   "source": [
    "state = 'UT'\n",
    "county = \"Utah\"\n",
    "fo = mesowest.urlopen(\"\"\"https://api.synopticlabs.org/v2/stations/metadata?&token=demotoken&state=%s&county=%s&vars=PM_25_concentration&status=active\"\"\"%(state, quote(county)))\n",
    "stations_ca = json.loads(fo.read())\n",
    "fo.close()\n",
    "\n",
    "\n",
    "station_data = [(\";\".join((s[\"STID\"],s['NAME'])),locale.atof(s['LATITUDE']),locale.atof(s['LONGITUDE'])) for s in stations_ca['STATION']]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "format": "row"
   },
   "outputs": [],
   "source": [
    "lat = np.mean([s[1] for s in ca_station_data])\n",
    "lon = np.mean([s[2] for s in ca_station_data])\n",
    "ca_map = folium.Map(location=[lat,lon], tiles=\"Stamen Terrain\", zoom_start=6.5)\n",
    "for s in ca_station_data:\n",
    "    folium.Marker([s[1], s[2]],\n",
    "                  popup=s[0],\n",
    "                  icon=folium.Icon(icon='cloud')).add_to(ca_map)\n",
    "ca_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map = folium.Map(location=[40.76623, -111.84755], tiles=\"Stamen Terrain\", zoom_start=7.5)\n",
    "map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "map = folium.Map(location=[40.76623, -111.84755], tiles=\"Stamen Terrain\", zoom_start=7.5)\n",
    "for s in station_data:\n",
    "    #print(s)\n",
    "    rslt = folium.Marker([s[1], s[2]],\n",
    "                  popup=s[0],\n",
    "                  icon=folium.Icon(icon='cloud')).add_to(map)\n",
    "    #print(rslt)\n",
    "    #print()\n",
    "map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\"token\":\"demotoken\",\n",
    "           \"state\":\"UT\",\n",
    "           \"county\":\"Salt Lake\",\n",
    "           \"vars\":\"PM_25_concentration\",\n",
    "           \"status\":\"active\"}\n",
    "r = requests.get(\"\"\"https://api.synopticlabs.org/v2/stations/metadata\"\"\", params=payload)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.json()[\"STATION\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_id = {}\n",
    "for s in r.json()[\"STATION\"]:\n",
    "    try:\n",
    "        station_id[s['STID']] = {\n",
    "               \"ELEVATION\":s[\"ELEVATION\"],\n",
    "               \"LONGITUDE\":s[\"LONGITUDE\"],\n",
    "               \"LATITUDE\":s[\"LATITUDE\"]}\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We can get a quick plot of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "may24 = pd.DataFrame.from_dict(r.json()[\"STATION\"][0][\"OBSERVATIONS\"]).dropna()\n",
    "may24.plot(x=\"date_time\", rot=45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Secondary Axis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This takes a little more work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ax1 = may24.plot(y=\"ozone_concentration_set_1\", x=\"date_time\", color='blue', grid=True, label='ozone', rot=45)\n",
    "ax2 = may24.plot(y=\"PM_25_concentration_set_1\", x=\"date_time\", color='red', grid=True, \n",
    "           secondary_y=True, label='pm25', ax=ax1, rot=45)\n",
    "\n",
    "ax1.set_ylabel(\"Ozone\")\n",
    "ax2.set_ylabel(\"pm25\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Third party dealing with dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* https://github.com/dateutil/dateutil\n",
    "* https://github.com/scrapinghub/dateparser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect Time Series Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    start = parse(\"January 1, 2019 12:00am MDT\").strftime(\"%Y%m%d%H%M\")\n",
    "    end   = parse(\"March 31, 2019 12:59 pm MDT\").strftime(\"%Y%m%d%H%M\")\n",
    "    data = {}\n",
    "    for s in station_id:\n",
    "        payload = {\"token\":\"demotoken\",\n",
    "                   \"stid\":s[\"stid\"],\n",
    "                   \"start\":start,\n",
    "                   \"end\":end,\n",
    "                   \"obtimezone\":\"LOCAL\",\n",
    "                   \"vars\":\"PM_25_concentration,ozone_concentration\",\n",
    "                   \"output\":\"json\"}\n",
    "        r = requests.get(\"\"\"http://api.mesowest.net/v2/stations/timeseries\"\"\", params=payload)\n",
    "        data[s[\"stid\"]]= r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    with open(\"pm25_03_slc_01012019_03312019.json\", \"w\") as f0:\n",
    "        json.dump(data,f0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    with open(\"pm25_03_slc_01012019_03312019.json\", \"r\") as f0:\n",
    "        data = json.load(f0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We need to parse dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = {}\n",
    "fails = []\n",
    "for key, value in data.items():\n",
    "    try:\n",
    "        dfs[key] = pd.DataFrame.from_dict(value[\"STATION\"][0][\"OBSERVATIONS\"]).dropna()\n",
    "        dfs[key][\"date_time\"] = pd.to_datetime(dfs[key][\"date_time\"])\n",
    "    except:\n",
    "        fails.append(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    with open(\"dfs.pickle\", \"wb\") as f0:\n",
    "        pickle.dump(dfs, f0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    with open(\"dfs.pickle\", \"rb\") as f0:\n",
    "        dfs = pickle.load(f0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feb01 = {}\n",
    "for key, value in dfs.items():\n",
    "    #print(value.keys())\n",
    "    feb01[key] = value[value.apply(lambda row: row[\"date_time\"].date() == date(2019,2,1), axis=1)]\n",
    "    #print(feb01[key].keys())\n",
    "    #print(\"-\"*22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feb01mean_pm25 = {}\n",
    "for key, value in feb01.items():\n",
    "    try:\n",
    "        feb01mean_pm25[key] = np.mean(value[\"PM_25_concentration_set_1\"])\n",
    "        #print(feb01mean_pm25.keys())\n",
    "    except Exception as error:\n",
    "        pass #print(key, error)\n",
    "#feb01mean_pm25.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feb01mean_O3 = {}\n",
    "for key, value in feb01.items():\n",
    "    try:\n",
    "        feb01mean_O3[key] = np.mean(value[\"ozone_concentration_set_1\"])\n",
    "    except:\n",
    "        pass #feb01mean[key] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Python\n",
    "station_id = [{\"stid\":s[\"STID\"],\n",
    "               \"ELEVATION\":s[\"ELEVATION\"],\n",
    "               \"LONGITUDE\":s[\"LONGITUDE\"],\n",
    "               \"LATITUDE\":s[\"LATITUDE\"]} for s in r.json()[\"STATION\"]]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a DataFrame with the mean values and lat/lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm25 = pd.DataFrame(\n",
    "       [[station_id[key][\"LONGITUDE\"],\n",
    "         station_id[key][\"LATITUDE\"],\n",
    "         feb01mean_pm25[key]] for key in feb01mean_pm25.keys()], columns=[\"long\", \"lat\", \"pm25\"], dtype=np.float64).dropna()\n",
    "pm25.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm25[\"lon_shift\"] = pm25[\"long\"] - np.min(pm25[\"long\"])\n",
    "pm25[\"lat_shift\"] = pm25[\"lat\"] - np.min(pm25[\"lat\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lllon = np.min(pm25[\"lon_shift\"])\n",
    "lllat = np.min(pm25[\"lat_shift\"])\n",
    "urlon = np.max(pm25[\"lon_shift\"])\n",
    "urlat = np.max(pm25[\"lat_shift\"])\n",
    "lllon, lllat, urlon, urlat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numcols = 128\n",
    "numrows = 128\n",
    "xi = np.linspace(np.min(pm25[\"long\"]), np.max(pm25[\"long\"]), numcols)\n",
    "yi = np.linspace(np.min(pm25[\"lat\"]), np.max(pm25[\"lat\"]), numrows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(pm25[\"pm25\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pm25[pm25[\"pm25\"] >= 2.0]\n",
    "# interpolate, there are better methods, especially if you have many datapoints\n",
    "tri_grid = tri.Triangulation(tmp[\"long\"],tmp[\"lat\"])\n",
    "interpolator = tri.LinearTriInterpolator(tri_grid, tmp[\"pm25\"])\n",
    "Xi, Yi = np.meshgrid(xi, yi)\n",
    "pm25i = interpolator(Xi, Yi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(pm25i), np.max(pm25i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(nrows=2)\n",
    "ax1.contour(xi, yi, pm25i, levels=10, linewidths=0.5, colors='k', axes=\"equal\")\n",
    "cntr1 = ax1.contourf(xi, yi, pm25i, levels=10, cmap=\"RdBu_r\", axes=\"equal\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(pm25i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=tmp[\"long\"], y=tmp[\"lat\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, row in pm25.iterrows():\n",
    "    print(row[\"pm25\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _,row in pm25.iterrows():\n",
    "    print(row)\n",
    "    print(\"-\"*22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in pm25[\"pm25\"]:\n",
    "    print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?np.min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nan in pm25[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
